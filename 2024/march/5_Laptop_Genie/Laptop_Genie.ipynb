{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankujuniyal/Gen-AI-Cohort/blob/main/2024/march/5_Laptop_Genie/Laptop_Genie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Required Libraries"
      ],
      "metadata": {
        "id": "IkN_Q5y7JMBa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY4YNRy-JDbK",
        "outputId": "88adf541-bd4d-4a1f-eb3b-e24e880cf279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.2 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.2)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.2->google-generativeai) (1.23.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.18.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shop Assistant"
      ],
      "metadata": {
        "id": "JU6K2iSj9TT_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hello world with Gemini Pro"
      ],
      "metadata": {
        "id": "nw0YFxxcJo6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# api_key = \"AIzaSyCMsjEYp9ctvpVGOdGZw-49sOrGXm5jS6w\""
      ],
      "metadata": {
        "id": "BTDNi5qQJQXb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "genai.configure(api_key=api_key)\n",
        "api_key = userdata.get('api_key')"
      ],
      "metadata": {
        "id": "lcDkzPo_JWo0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "chat = model.start_chat(history = [])"
      ],
      "metadata": {
        "id": "wEFt9d5mJXBz"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_prompt(prompt, model=model):\n",
        "  response = model.generate_content(prompt)\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "5oHD9RdRJtSK"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Who is the prime minister of India ?\"\n",
        "execute_prompt(prompt, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "blRLc5YaJw21",
        "outputId": "bd13df9d-c971-47de-c7ab-5f32da7e9981"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Narendra Modi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage 1: Intent Clarity and Intent Confirmation"
      ],
      "metadata": {
        "id": "-ReKG7_V9nwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start Conversation"
      ],
      "metadata": {
        "id": "m6ftV-dQ9ub2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-pro')\n",
        "chat = model.start_chat(history = [])\n",
        "\n",
        "def get_system_message():\n",
        "    delimiter = \"####\"\n",
        "    example_user_req = {'GPU intensity': 'high','Display quality': 'high','Portability': 'low','Multitasking': 'high','Processing speed': 'high','Budget': '150000'}\n",
        "\n",
        "    system_message = f\"\"\"\n",
        "    You are an intelligent laptop gadget expert and your goal is to find the best laptop for a user.\n",
        "    You need to ask relevant questions and understand the user profile by analysing the user's responses.\n",
        "    You final objective is to fill the values for the different keys ('GPU intensity','Display quality','Portability','Multitasking','Processing speed','Budget') in the python dictionary and be confident of the values.\n",
        "    These key value pairs define the user's profile.\n",
        "    The python dictionary looks like this {{'GPU intensity': 'values','Display quality': 'values','Portability': 'values','Multitasking': 'values','Processing speed': 'values','Budget': 'values'}}\n",
        "    The values for all keys, except 'budget', should be 'low', 'medium', or 'high' based on the importance of the corresponding keys, as stated by user.\n",
        "    The value for 'budget' should be a numerical value extracted from the user's response.\n",
        "    The values currently in the dictionary are only representative values.\n",
        "\n",
        "    {delimiter}Here are some instructions around the values for the different keys. If you do not follow this, you'll be heavily penalised.\n",
        "    - The values for all keys, except 'Budget', should strictly be either 'low', 'medium', or 'high' based on the importance of the corresponding keys, as stated by user.\n",
        "    - The value for 'budget' should be a numerical value extracted from the user's response.\n",
        "    - 'Budget' value needs to be greater than or equal to 25000 INR. If the user says less than that, please mention that there are no laptops in that range.\n",
        "    - Do not randomly assign values to any of the keys. The values need to be inferred from the user's response.\n",
        "    {delimiter}\n",
        "\n",
        "    To fill the dictionary, you need to have the following chain of thoughts:\n",
        "    {delimiter} Thought 1: Ask a question to understand the user's profile and requirements. \\n\n",
        "    If their primary use for the laptop is unclear. Ask another question to comprehend their needs.\n",
        "    You are trying to fill the values of all the keys ('GPU intensity','Display quality','Portability','Multitasking','Processing speed','Budget') in the python dictionary by understanding the user requirements.\n",
        "    Identify the keys for which you can fill the values confidently using the understanding. \\n\n",
        "    Remember the instructions around the values for the different keys.\n",
        "    Answer \"Yes\" or \"No\" to indicate if you understand the requirements and have updated the values for the relevant keys. \\n\n",
        "    If yes, proceed to the next step. Otherwise, rephrase the question to capture their profile. \\n{delimiter}\n",
        "\n",
        "    {delimiter}Thought 2: Now, you are trying to fill the values for the rest of the keys which you couldn't in the previous step.\n",
        "    Remember the instructions around the values for the different keys. Ask questions you might have for all the keys to strengthen your understanding of the user's profile.\n",
        "    Answer \"Yes\" or \"No\" to indicate if you understood all the values for the keys and are confident about the same.\n",
        "    If yes, move to the next Thought. If no, ask question on the keys whose values you are unsure of. \\n\n",
        "    It is a good practice to ask question with a sound logic as opposed to directly citing the key you want to understand value for.{delimiter}\n",
        "\n",
        "    {delimiter}Thought 3: Check if you have correctly updated the values for the different keys in the python dictionary.\n",
        "    If you are not confident about any of the values, ask clarifying questions. {delimiter}\n",
        "\n",
        "    Follow the above chain of thoughts and only output the final updated python dictionary. \\n\n",
        "\n",
        "\n",
        "    {delimiter} Here is a sample conversation between the user and assistant:\n",
        "    user: \"Hi, I am an editor.\"\n",
        "    model: \"Great! As an editor, you likely require a laptop that can handle demanding tasks. Hence, the laptop should have high multitasking capability. You would also need a high end display for better visuals and editing. May I know what kind of work do you primarily focus on? Are you more involved in video editing, photo editing, or both? Understanding the specific type of editing work will help me tailor my recommendations accordingly. Let me know if my understanding is correct until now.\"\n",
        "    user: \"I primarily work with After Effects.\"\n",
        "    model: \"Thank you for providing that information. Working with After Effects involves working with graphics, animations, and rendering, which will require high GPU. Do you work with high-resolution media files, such as 4K videos or RAW photos? Understanding your file sizes will help determine the storage capacity and processing power needed.\"\n",
        "    user: \"Yes, sometimes I work with 4K videos as well.\"\n",
        "    model: \"Thank you for the information. Processing 4K vidoes will require a good processor and high GPU. I think we have already determined earlier that you need a high GPU. To ensure I have a complete understanding of your needs, I have one more question: Are you frequently on the go and require a laptop that is lightweight and easy to carry, or do you primarily work from a stationary location?\"\n",
        "    user: \"Yes, sometimes I travel but do not carry my laptop.\"\n",
        "    model:\"Could you kindly let me know your budget for the laptop? This will help me find options that fit within your price range while meeting the specified requirements.\"\n",
        "    user: \"my max budget is 1.5lakh inr\"\n",
        "    model: \"{example_user_req}\"\n",
        "    {delimiter}\n",
        "\n",
        "    Start with a short welcome message and encourage the user to share their requirements.\n",
        "    \"\"\"\n",
        "    return system_message"
      ],
      "metadata": {
        "id": "H2r9tE9-JzUr"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = get_system_message()"
      ],
      "metadata": {
        "id": "ZDaXgIIFKJqa"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(system_message)"
      ],
      "metadata": {
        "id": "hYUG3LblYBsH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxez0SIq985U",
        "outputId": "6c50cacf-f45f-4bf2-d9c3-52e4fd729424"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi there! I am here to help you find the best laptop for your needs. Could you please share what you are primarily going to be using the laptop for?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chat.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYG5tISP988P",
        "outputId": "16c79ca6-632f-4afd-ed62-f9095b9793b1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX3yS0mq-B7T",
        "outputId": "bd1a57a4-0302-4548-d75e-ed99c06c3092"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[parts {\n",
            "  text: \"\\n    You are an intelligent laptop gadget expert and your goal is to find the best laptop for a user.\\n    You need to ask relevant questions and understand the user profile by analysing the user\\'s responses.\\n    You final objective is to fill the values for the different keys (\\'GPU intensity\\',\\'Display quality\\',\\'Portability\\',\\'Multitasking\\',\\'Processing speed\\',\\'Budget\\') in the python dictionary and be confident of the values.\\n    These key value pairs define the user\\'s profile.\\n    The python dictionary looks like this {\\'GPU intensity\\': \\'values\\',\\'Display quality\\': \\'values\\',\\'Portability\\': \\'values\\',\\'Multitasking\\': \\'values\\',\\'Processing speed\\': \\'values\\',\\'Budget\\': \\'values\\'}\\n    The values for all keys, except \\'budget\\', should be \\'low\\', \\'medium\\', or \\'high\\' based on the importance of the corresponding keys, as stated by user.\\n    The value for \\'budget\\' should be a numerical value extracted from the user\\'s response.\\n    The values currently in the dictionary are only representative values.\\n\\n    ####Here are some instructions around the values for the different keys. If you do not follow this, you\\'ll be heavily penalised.\\n    - The values for all keys, except \\'Budget\\', should strictly be either \\'low\\', \\'medium\\', or \\'high\\' based on the importance of the corresponding keys, as stated by user.\\n    - The value for \\'budget\\' should be a numerical value extracted from the user\\'s response.\\n    - \\'Budget\\' value needs to be greater than or equal to 25000 INR. If the user says less than that, please mention that there are no laptops in that range.\\n    - Do not randomly assign values to any of the keys. The values need to be inferred from the user\\'s response.\\n    ####\\n\\n    To fill the dictionary, you need to have the following chain of thoughts:\\n    #### Thought 1: Ask a question to understand the user\\'s profile and requirements. \\n\\n    If their primary use for the laptop is unclear. Ask another question to comprehend their needs.\\n    You are trying to fill the values of all the keys (\\'GPU intensity\\',\\'Display quality\\',\\'Portability\\',\\'Multitasking\\',\\'Processing speed\\',\\'Budget\\') in the python dictionary by understanding the user requirements.\\n    Identify the keys for which you can fill the values confidently using the understanding. \\n\\n    Remember the instructions around the values for the different keys.\\n    Answer \\\"Yes\\\" or \\\"No\\\" to indicate if you understand the requirements and have updated the values for the relevant keys. \\n\\n    If yes, proceed to the next step. Otherwise, rephrase the question to capture their profile. \\n####\\n\\n    ####Thought 2: Now, you are trying to fill the values for the rest of the keys which you couldn\\'t in the previous step.\\n    Remember the instructions around the values for the different keys. Ask questions you might have for all the keys to strengthen your understanding of the user\\'s profile.\\n    Answer \\\"Yes\\\" or \\\"No\\\" to indicate if you understood all the values for the keys and are confident about the same.\\n    If yes, move to the next Thought. If no, ask question on the keys whose values you are unsure of. \\n\\n    It is a good practice to ask question with a sound logic as opposed to directly citing the key you want to understand value for.####\\n\\n    ####Thought 3: Check if you have correctly updated the values for the different keys in the python dictionary.\\n    If you are not confident about any of the values, ask clarifying questions. ####\\n\\n    Follow the above chain of thoughts and only output the final updated python dictionary. \\n\\n\\n\\n    #### Here is a sample conversation between the user and assistant:\\n    user: \\\"Hi, I am an editor.\\\"\\n    model: \\\"Great! As an editor, you likely require a laptop that can handle demanding tasks. Hence, the laptop should have high multitasking capability. You would also need a high end display for better visuals and editing. May I know what kind of work do you primarily focus on? Are you more involved in video editing, photo editing, or both? Understanding the specific type of editing work will help me tailor my recommendations accordingly. Let me know if my understanding is correct until now.\\\"\\n    user: \\\"I primarily work with After Effects.\\\"\\n    model: \\\"Thank you for providing that information. Working with After Effects involves working with graphics, animations, and rendering, which will require high GPU. Do you work with high-resolution media files, such as 4K videos or RAW photos? Understanding your file sizes will help determine the storage capacity and processing power needed.\\\"\\n    user: \\\"Yes, sometimes I work with 4K videos as well.\\\"\\n    model: \\\"Thank you for the information. Processing 4K vidoes will require a good processor and high GPU. I think we have already determined earlier that you need a high GPU. To ensure I have a complete understanding of your needs, I have one more question: Are you frequently on the go and require a laptop that is lightweight and easy to carry, or do you primarily work from a stationary location?\\\"\\n    user: \\\"Yes, sometimes I travel but do not carry my laptop.\\\"\\n    model:\\\"Could you kindly let me know your budget for the laptop? This will help me find options that fit within your price range while meeting the specified requirements.\\\"\\n    user: \\\"my max budget is 1.5lakh inr\\\"\\n    model: \\\"{\\'GPU intensity\\': \\'high\\', \\'Display quality\\': \\'high\\', \\'Portability\\': \\'low\\', \\'Multitasking\\': \\'high\\', \\'Processing speed\\': \\'high\\', \\'Budget\\': \\'150000\\'}\\\"\\n    ####\\n\\n    Start with a short welcome message and encourage the user to share their requirements.\\n    \"\n",
            "}\n",
            "role: \"user\"\n",
            ", parts {\n",
            "  text: \"Hi there! I am here to help you find the best laptop for your needs. Could you please share what you are primarily going to be using the laptop for?\"\n",
            "}\n",
            "role: \"model\"\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User input and Intent Clarity\n",
        "\n",
        "Start user conversation"
      ],
      "metadata": {
        "id": "fpuhHBXILvTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_message = \"I need a laptop for backend development\"\n",
        "response = chat.send_message(user_message)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "YaYeco_PKmi7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c9c020c4-547f-41cb-f12a-5f50bb598473"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I see. Backend development involves working with databases, servers, and code. For this, you would need a laptop with good processing speed and multitasking capabilities. Would you say that is an accurate assessment of your requirements? Also, do you have any preferences for the display quality or portability of the laptop?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "debug_response_assistant = response.text"
      ],
      "metadata": {
        "id": "hoFozAd8L79b"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chat.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hizfZw0hbl2p",
        "outputId": "4afb10f0-aa4a-436d-9581-34b89819b631"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intent Confirmation Layer"
      ],
      "metadata": {
        "id": "jc9hTlYCL8Yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "def execute_prompt(prompt, model=model):\n",
        "  response = model.generate_content(prompt)\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "zfEC_i-9_sp3"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intent_confirmation_layer(message: str, model=model):\n",
        "    delimiter = \"####\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a senior evaluator who has an eye for detail.\n",
        "    You are provided an input. You need to evaluate if the input has the following keys: 'GPU intensity','Display quality','Portability','Multitasking',' Processing speed','Budget'\n",
        "    Next you need to evaluate if the keys have the the values filled correctly.\n",
        "    The values for all keys, except 'budget', should be 'low', 'medium', or 'high' based on the importance as stated by user. The value for the key 'budget' needs to contain a number with currency.\n",
        "    Output a string 'Yes' if the input contains the dictionary with the values correctly filled for all keys.\n",
        "    Otherwise out the string 'No'.\n",
        "    Here are some input output pairs for better understanding:\n",
        "    input: {{'GPU intensity': 'low', 'Display quality': 'high', 'Portability': 'low', 'Multitasking': 'high', 'Processing speed': 'medium', 'Budget': '50000'}}\n",
        "    output: Yes\n",
        "    input: {{'Display quality': 'high', 'Portability': 'low', 'Multitasking': 'high', 'Processing speed': 'medium', 'Budget': '50000'}}\n",
        "    output: No\n",
        "    input: {{'Portability': 'low', 'Multitasking': 'high', 'Processing speed': 'medium', 'Budget': '50000'}}\n",
        "    output: No\n",
        "    input: {{'Multitasking': 'high', 'Processing speed': 'medium', 'Budget': '50000'}}\n",
        "    output: No\n",
        "    input: {{'Budget': '50000'}}\n",
        "    output: No\n",
        "\n",
        "    Here is the input: {message}\n",
        "    Only output a one-word string - Yes/No.\n",
        "    \"\"\"\n",
        "    return execute_prompt(prompt, model)"
      ],
      "metadata": {
        "id": "kOM6ZlSbL8_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "debug_confirmation = intent_confirmation_layer(message = debug_response_assistant, model = model)\n",
        "print(debug_confirmation)"
      ],
      "metadata": {
        "id": "ET4DVHhwMA0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "debug_response_assistant = \"{'GPU intensity': 'low', 'Display quality': 'medium', 'Portability': 'low', 'Multitasking': 'low', 'Processing speed': 'high', 'Budget': '80000'}\"\n",
        "debug_confirmation = intent_confirmation_layer(debug_response_assistant)\n",
        "print(debug_confirmation)"
      ],
      "metadata": {
        "id": "iVznnwqniJPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dictionary Conversion Layer (From String to python dict)"
      ],
      "metadata": {
        "id": "LU4As9hzAByv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import ast\n",
        "\n",
        "def extract_dictionary_from_string(string: str) -> dict:\n",
        "  # Use regular expression to extract exact dictionary part\n",
        "  regex_pattern = r\"\\{[^{}]+\\}\"\n",
        "  dictionary_matches = re.findall(regex_pattern, string)\n",
        "  dictionary = {}\n",
        "  try:\n",
        "    if dictionary_matches:\n",
        "      dictionary_match = dictionary_matches[0]\n",
        "      dictionary_string = dictionary_match.lower()\n",
        "\n",
        "      # Convert dictionary string into a python dictionary\n",
        "      dictionary = ast.literal_eval(dictionary_string)\n",
        "  except BaseException as e:\n",
        "    dictionary = {}\n",
        "    print(f\"exception : {e}\")\n",
        "  return dictionary"
      ],
      "metadata": {
        "id": "9PLEGNd9AF3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "debug_response_assistant_n = \"\"\"\n",
        "Thank you for providing your budget.\n",
        "\n",
        "Based on your requirements and a budget of 80,000 INR, I would recommend the following laptops:\n",
        "\n",
        "**Option 1: Dell XPS 13**\n",
        "\n",
        "* **Pros:** Lightweight and portable, excellent display quality, good battery life\n",
        "* **Cons:** Limited upgradability, can be expensive\n",
        "\n",
        "**Option 2: Apple MacBook Air M2**\n",
        "\n",
        "* **Pros:** Lightweight and thin, powerful M2 chip, long battery life\n",
        "* **Cons:** Limited ports, can be expensive\n",
        "\n",
        "**Option 3: Lenovo ThinkPad X1 Carbon**\n",
        "\n",
        "* **Pros:** Durable and well-built, good display quality, excellent keyboard\n",
        "* **Cons:** Can be expensive, limited battery life\n",
        "\n",
        "These laptops offer a good balance of portability, performance, and display quality, making them suitable for backend development tasks. They also fit within your budget of 80,000 INR.\n",
        "\n",
        "Please let me know if you have any questions or if there are any other factors I should consider in my recommendations.\n",
        "\n",
        "**Final Python Dictionary:**\n",
        "\n",
        "```\n",
        "{'GPU intensity': 'low', 'Display quality': 'medium', 'Portability': 'high', 'Multitasking': 'low', 'Processing speed': 'high', 'Budget': '80000'}\n",
        "```\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xNucHWBMAF75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_dict_n = extract_dictionary_from_string(debug_response_assistant_n)\n",
        "print(response_dict_n)"
      ],
      "metadata": {
        "id": "IKokmSGJAGG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(response_dict_n)"
      ],
      "metadata": {
        "id": "AtZYMXFuQK7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Integrate Stage 1"
      ],
      "metadata": {
        "id": "EK2CyinkA1dE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def intent_clarity_and_intent_confirmation_layer():\n",
        "  # Initialize model and chat instance\n",
        "  model = genai.GenerativeModel('gemini-pro')\n",
        "  chat = model.start_chat(history = [])\n",
        "\n",
        "  # Initialize system_message and print welcome message\n",
        "  system_message = get_system_message()\n",
        "  response = chat.send_message(system_message)\n",
        "  print(response.text)\n",
        "\n",
        "  # Get user input\n",
        "  user_input = input(\"\")\n",
        "\n",
        "  user_intent = None\n",
        "  while \"exit\" not in user_input.lower():\n",
        "    response = chat.send_message(user_input).text\n",
        "    confirmation = intent_confirmation_layer(response)\n",
        "    print(\"Intent confirmation : \", confirmation)\n",
        "\n",
        "    if \"No\" in confirmation:\n",
        "      print(\"Model  :: \",response)\n",
        "      user_input = input(\"\")\n",
        "      continue\n",
        "    else:\n",
        "      user_intent = extract_dictionary_from_string(response)\n",
        "      break\n",
        "\n",
        "  print(\"User intent --- \", user_intent)\n",
        "  return user_intent"
      ],
      "metadata": {
        "id": "f31ry0-5AGSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intent_clarity_and_intent_confirmation_layer()"
      ],
      "metadata": {
        "id": "NmAsBmWUqAqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage 2: Product Mapping and Information Extraction"
      ],
      "metadata": {
        "id": "5BdzF84FWw-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Re-Initialize Model"
      ],
      "metadata": {
        "id": "YQAXUJ7UWzUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-pro')\n",
        "chat = model.start_chat(history = [])"
      ],
      "metadata": {
        "id": "crXjPBtSW1aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "XkojWH3PW9CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "laptop_df= pd.read_csv('laptop_data.csv')\n",
        "\n",
        "laptop_df.head()"
      ],
      "metadata": {
        "id": "Cw11gnN1W-aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "laptop_df.shape"
      ],
      "metadata": {
        "id": "jGjf9BdKXSCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "description = laptop_df.Description[0]\n",
        "description"
      ],
      "metadata": {
        "id": "PBiXC7O6YUCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def product_map_layer(laptop_description):\n",
        "\n",
        "  delimiter = \"#####\"\n",
        "  lap_spec = {\n",
        "      \"GPU intensity\":\"(Type of the Graphics Processor)\",\n",
        "      \"Display quality\":\"(Display Type, Screen Resolution, Display Size)\",\n",
        "      \"Portability\":\"(Laptop Weight)\",\n",
        "      \"Multitasking\":\"(RAM Size)\",\n",
        "      \"Processing speed\":\"(CPU Type, Core, Clock Speed)\"\n",
        "  }\n",
        "\n",
        "  values = {'low','medium','high'}\n",
        "\n",
        "  prompt=f\"\"\"\n",
        "  You are a Laptop Specifications Classifier whose job is to extract the key features of laptops as per their requirements.\n",
        "  To analyze each laptop, perform the following steps:\n",
        "  Step 1: Extract the laptop's primary features from the description {laptop_description}\n",
        "  Step 2: Store the extracted features in {lap_spec} \\\n",
        "  Step 3: Classify each of the items in {lap_spec}into {values} based on the following rules: \\\n",
        "  {delimiter}\n",
        "  GPU Intensity: low: < for Integrated graphics or entry-level dedicated graphics like Intel UHD > , \\n\n",
        "  medium: < if Mid-range dedicated graphics like M1, AMD Radeon, Intel Iris > , \\n\n",
        "  high: < High-end dedicated graphics like Nvidia > , \\n\n",
        "\n",
        "  Display Quality: low: < if resolution below Full HD (e.g., 1366x768). > , \\n\n",
        "  medium: < if Full HD resolution (1920x1080) or higher. > , \\n\n",
        "  high: < if High-resolution display (e.g., 4K, Retina) with excellent color accuracy and features like HDR support. > \\n\n",
        "\n",
        "  Portability: low: < if laptop weight is less than 1.51 kg > , \\n\n",
        "  medium: < if laptop weight is between 1.51 kg and 2.51 kg> , \\n\n",
        "  high: <if laptop weight is greater than 2.51 kg> \\n\n",
        "\n",
        "  Multitasking: low: < If RAM size is 8GB, 12GB > , \\n\n",
        "  medium: < if RAM size is 16GB > , \\n\n",
        "  high: < if RAM size is 32GB, 64GB> \\n\n",
        "\n",
        "  Processing Speed: low: < if entry-level processors like Intel Core i3, AMD Ryzen 3> , \\n\n",
        "  medium: < if Mid-range processors like Intel Core i5, AMD Ryzen 5 > , \\n\n",
        "  high: < if High-performance processors like Intel Core i7, AMD Ryzen 7 or higher > \\n\n",
        "  {delimiter}\n",
        "\n",
        "  {delimiter}\n",
        "  Here are some input output pairs for few-shot learning:\n",
        "  input1: \"The Dell Inspiron is a versatile laptop that combines powerful performance and affordability. It features an Intel Core i5 processor clocked at 2.4 GHz, ensuring smooth multitasking and efficient computing. With 8GB of RAM and an SSD, it offers quick data access and ample storage capacity. The laptop sports a vibrant 15.6\" LCD display with a resolution of 1920x1080, delivering crisp visuals and immersive viewing experience. Weighing just 2.5 kg, it is highly portable, making it ideal for on-the-go usage. Additionally, it boasts an Intel UHD GPU for decent graphical performance and a backlit keyboard for enhanced typing convenience. With a one-year warranty and a battery life of up to 6 hours, the Dell Inspiron is a reliable companion for work or entertainment. All these features are packed at an affordable price of 35,000, making it an excellent choice for budget-conscious users.\"\n",
        "  output1: {{'GPU intensity': 'medium','Display quality':'medium','Portability':'medium','Multitasking':'high','Processing speed':'medium'}}\n",
        "\n",
        "  input2: \"The Lenovo ThinkPad X1 Carbon is a sleek and lightweight laptop designed for professionals on the go. It is equipped with an Intel Core i7 processor running at 2.6 GHz, providing strong processing capabilities for multitasking and productivity. With 16GB of RAM and an SSD, it offers fast and efficient performance along with ample storage capacity. The laptop features a 14\" IPS display with a resolution of 2560x1440, delivering sharp visuals and accurate colors. It comes with Intel UHD integrated graphics for decent graphical performance. Weighing just 1.13 kg, it is extremely lightweight and highly portable. The laptop features an IR camera for face unlock, providing convenient and secure login options. With a three-year warranty and an impressive battery life of up to 12 hours, the Lenovo ThinkPad X1 Carbon ensures reliability and long-lasting productivity. Priced at 130,000, it offers top-notch performance and portability for professionals.\"\n",
        "  output2: {{'GPU intensity': 'medium', 'Display quality': 'high', 'Portability': 'high', 'Multitasking':'high', 'Processing speed':'high'}}\n",
        "\n",
        "  input3: \"The Apple MacBook Pro is a high-end laptop that combines top-tier performance with a stunning display. It is equipped with an Intel Core i9 processor running at 2.9 GHz, providing exceptional processing power for demanding tasks and content creation. With 32GB of RAM and an SSD, it offers seamless multitasking and fast storage access for large projects. The laptop features a 16\" Retina display with a resolution of 3072x1920, delivering breathtaking visuals and precise color reproduction. It comes with an AMD Radeon graphics card, ensuring smooth graphics performance for professional applications. Weighing 2.02 kg, it is relatively lightweight for its size. The laptop features a True Tone display, adjusting the color temperature to match the ambient lighting for a more natural viewing experience. With a three-year warranty and a battery life of up to 10 hours, the Apple MacBook Pro offers reliability and endurance for professionals. Priced at 280,000, it caters to users who require uncompromising performance and a superior display for their demanding workloads.\"\n",
        "  output3: {{'GPU intensity': 'medium', 'Display quality': 'high', 'Portability': 'medium','Multitasking': 'high', 'Processing speed': 'high'}}\n",
        "  {delimiter}\n",
        "\n",
        "  Follow the above instructions step-by-step and output the dictionary {lap_spec} for the following laptop {laptop_description}.\n",
        "  \"\"\"\n",
        "\n",
        "  #see that we are using the Completion endpoint and not the Chatcompletion endpoint\n",
        "  return execute_prompt(prompt).lower()"
      ],
      "metadata": {
        "id": "Ksm-nYQ_Y8wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "laptop_feature = product_map_layer(description)\n",
        "laptop_feature"
      ],
      "metadata": {
        "id": "PKZyB6F9bBZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column \"laptop_feature\" that contains the dictionary of the product features\n",
        "laptop_df['laptop_feature'] = laptop_df['Description'].apply(lambda x: product_map_layer(x))"
      ],
      "metadata": {
        "id": "TJmhmT0fbdts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "laptop_df.head()"
      ],
      "metadata": {
        "id": "KV6gid-gbeLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "laptop_df.to_csv(\"updated_laptop.csv\", index=False,header = True)"
      ],
      "metadata": {
        "id": "-RxQOLZObg5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "NeWFi7dnbiSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Product Information Extraction"
      ],
      "metadata": {
        "id": "MiYTnhMXhZwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_laptop_with_user_req(user_req):\n",
        "  user_budget = user_req.get(\"budget\", 0)\n",
        "  print(\"user_req : \", user_req)\n",
        "  print(\"user_budget : \", user_budget)\n",
        "\n",
        "  # Load laptop dataframe\n",
        "  laptop_df= pd.read_csv('updated_laptop.csv')\n",
        "  filtered_laptops = laptop_df.copy()\n",
        "\n",
        "  # Filter laptops whose price is less than or equal to user_budget\n",
        "  filtered_laptops['Price'] = filtered_laptops['Price'].str.replace(\",\", \"\").astype(int)\n",
        "  filtered_laptops = filtered_laptops[filtered_laptops.Price <= user_budget].copy()\n",
        "\n",
        "  mappings = {'low': 0, 'medium': 1, 'high': 2}\n",
        "\n",
        "  # Create Score column in dataframe and initialize it to 0\n",
        "  filtered_laptops['Score'] = 0\n",
        "  # Calculate score based on user_req\n",
        "  for index, row in filtered_laptops.iterrows():\n",
        "    user_product_match_str = row['laptop_feature']\n",
        "    laptop_values = extract_dictionary_from_string(user_product_match_str)\n",
        "    print(\"laptop_values : \", laptop_values)\n",
        "    score = 0\n",
        "\n",
        "    for key, user_value in user_req.items():\n",
        "      if key == 'budget':\n",
        "        continue # Skip budget comparision, its buisness requirement\n",
        "\n",
        "      laptop_value = laptop_values.get(key, None)\n",
        "      print(f\"key : {key}, laptop_value : {laptop_value}\")\n",
        "\n",
        "      laptop_mappings = mappings.get(laptop_value, -1)\n",
        "      user_mappings = mappings.get(user_value, -1)\n",
        "\n",
        "      # If the laptop value is greater than or equal to the user value then increment score by 1\n",
        "      if laptop_mappings >= user_mappings:\n",
        "        score += 1\n",
        "\n",
        "    filtered_laptops.loc[index, 'Score'] = score\n",
        "\n",
        "  # Sort the laptops by score in descending order and return top 3 products\n",
        "  top_laptops = filtered_laptops.drop('laptop_feature', axis=1)\n",
        "  top_laptops = top_laptops.sort_values('Score', ascending=False).head(3)\n",
        "  print(\"top_laptops :\", top_laptops)\n",
        "\n",
        "  return top_laptops.to_json(orient='records')"
      ],
      "metadata": {
        "id": "rCTX0xQRhXRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_req = {'gpu intensity': 'low', 'display quality': 'low', 'portability': 'high', 'multitasking': 'low', 'processing speed': 'high', 'budget': 80000}\n",
        "type(user_req)"
      ],
      "metadata": {
        "id": "S8MJkVA6hb_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_3_laptops = compare_laptop_with_user_req(user_req)"
      ],
      "metadata": {
        "id": "Tk60c7rZhdi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(top_3_laptops)"
      ],
      "metadata": {
        "id": "y9Qz1TqkhfUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Product Validation"
      ],
      "metadata": {
        "id": "wubK-Ju6Zjyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def recommendation_validation(laptop_recommendation):\n",
        "  data = json.loads(laptop_recommendation) # this will take input as a string and create output as list\n",
        "  data1 = []\n",
        "  for i in range(len(data)):\n",
        "    if data[i]['Score'] > 2:\n",
        "      data1.append(data[i])\n",
        "  return data1"
      ],
      "metadata": {
        "id": "Nf2dyOvmZkU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validated_data = recommendation_validation(top_3_laptops)\n",
        "print(validated_data)"
      ],
      "metadata": {
        "id": "WfcBq45wZll5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(validated_data)"
      ],
      "metadata": {
        "id": "w73vMM93ZpB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FInal step of Stage 2"
      ],
      "metadata": {
        "id": "gYLztrGBcvKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def product_mapping_and_information_extraction(user_req):\n",
        "  print(f\"data type of user_req = {type(user_req)}\")\n",
        "  top_3_laptops = compare_laptop_with_user_req(user_req)\n",
        "  validated_recod = recommendation_validation(top_3_laptops)\n",
        "  return validated_recod"
      ],
      "metadata": {
        "id": "z0j_waGqcl9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validated_recod = product_mapping_and_information_extraction(user_req)\n",
        "validated_recod"
      ],
      "metadata": {
        "id": "5bWwWNIKcmkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Re-Initialize Model"
      ],
      "metadata": {
        "id": "veo-sL61d7qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-pro')\n",
        "chat = model.start_chat(history = [])"
      ],
      "metadata": {
        "id": "04lGl7zTd9Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Product Recomendation"
      ],
      "metadata": {
        "id": "GWsrSjtKd-5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_conversation_for_product_recommendation(products):\n",
        "  system_message = f\"\"\"\n",
        "    You are an intelligent laptop gadget expert and you are tasked with the objective to solve the user \\\n",
        "    queries about any product from the catalogue: {products}. \\\n",
        "    You should keep the user profile in mind while answering the questions.\\\n",
        "\n",
        "    Start with a brief summary of each laptop in the following format, in decreasing order of price of laptops:\n",
        "    1. <Laptop Name>: <Majof specification of laptop>, <Price in Rs>\n",
        "    2. <Laptop Name>: <Majof specification of laptop>, <Price in Rs>\n",
        "  \"\"\"\n",
        "  response = chat.send_message(system_message)\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "SaS8JjkAeAeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = initialize_conversation_for_product_recommendation(top_3_laptops)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "rgU5kJUReCqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Integrate Stage_1, Stage_2 and Stage_3"
      ],
      "metadata": {
        "id": "BN0IAb4Sg2H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dialogue_mgmt_system():\n",
        "  model = genai.GenerativeModel('gemini-pro')\n",
        "  chat = model.start_chat(history = [])\n",
        "\n",
        "  # Stage 1:\n",
        "  user_intent = intent_clarity_and_intent_confirmation_layer()\n",
        "  print(\"------------------Stage 1 finish------------------\")\n",
        "\n",
        "  # Stage 2:\n",
        "  print(\" \\n \\n ------------------Stage 2 start------------------\")\n",
        "  validated_record = product_mapping_and_information_extraction(user_intent)\n",
        "  print(\" \\n \\n ------------------Stage 2 finish------------------\")\n",
        "\n",
        "  # Stage 3:\n",
        "  model = genai.GenerativeModel('gemini-pro')\n",
        "  chat = model.start_chat(history = [])\n",
        "  response = initialize_conversation_for_product_recommendation(validated_record)\n",
        "  print(\" \\n \\n ------------------Stage 3 finish------------------\")\n",
        "  print(f\"I can offer you the following choices from our current stock.\")\n",
        "  print(response)\n",
        "  print(\" \\n \\n ------ Thanks for Using Shop Assistant ------ \")\n"
      ],
      "metadata": {
        "id": "2XAc6t9fg3z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue_mgmt_system()"
      ],
      "metadata": {
        "id": "bknwRQJVg51O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat.history)"
      ],
      "metadata": {
        "id": "B_RbiNhBg8X-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}